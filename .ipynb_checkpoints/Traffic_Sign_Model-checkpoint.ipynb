{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Indentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install -r setup_lib.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from imageio import imread\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow\n",
    "import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Load Data ảnh có dạng *.ppm và nhãn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'GTSRB/Final_Training/Images'\n",
    "pixels = []\n",
    "labels = []\n",
    "# Loop qua các thư mục trong thư mục Images\n",
    "for dir in os.listdir(data_path):\n",
    "    # Bỏ qua file .DS_Store của máy MacOS\n",
    "    if dir == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    # Đọc file csv để lấy thông tin về ảnh\n",
    "    class_dir = os.path.join(data_path, dir)\n",
    "    info_file = pd.read_csv(os.path.join(class_dir, \"GT-\" + dir + '.csv'), sep=';')\n",
    "\n",
    "    # Lăp trong file\n",
    "    for row in info_file.iterrows():\n",
    "        # Đọc ảnh\n",
    "        pixel = imread(os.path.join(class_dir, row[1].Filename))\n",
    "        # Trích phần ROI theo thông tin trong file csv\n",
    "        pixel = pixel[row[1]['Roi.X1']:row[1]['Roi.X2'], row[1]['Roi.Y1']:row[1]['Roi.Y2'], :]\n",
    "        # Resize về kích cỡ chuẩn\n",
    "        img = cv2.resize(pixel, (64,64))\n",
    "\n",
    "        # Thêm vào list dữ liệu\n",
    "        pixels.append(img)\n",
    "\n",
    "        # Thêm nhãn cho ảnh\n",
    "        labels.append(row[1].ClassId)\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trộn dữ liệu và chia dữ liệu thành 3 phần với tỉ lệ Train:Validation:Test = 6:2:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hoá dữ liệu pixels và labels\n",
    "pixels = np.array(pixels)\n",
    "labels = keras.utils.np_utils.to_categorical(labels)\n",
    "\n",
    "# Nhào trộn dữ liệu ngẫu nhiên\n",
    "randomize = np.arange(len(pixels))\n",
    "np.random.shuffle(randomize)\n",
    "X = pixels[randomize]\n",
    "y = labels[randomize]\n",
    "\n",
    "print(\"X = \",X.shape)\n",
    "\n",
    "# Chia dữ liệu theo tỷ lệ 60% train và 40% còn lại cho val và test\n",
    "train_size = int(X.shape[0] * 0.6)\n",
    "X_train, X_val_test = X[:train_size], X[train_size:]\n",
    "y_train, y_val_test = y[:train_size], y[train_size:]\n",
    "\n",
    "val_size = int(X_val_test.shape[0] * 0.5) # 50% của phần 40% bên trên\n",
    "X_val, X_test = X_val_test[:val_size], X_val_test[val_size:]\n",
    "y_val, y_test = y_val_test[:val_size], y_val_test[val_size:]\n",
    "\n",
    "print(\"X_train = \",X_train.shape)\n",
    "print(\"X_val = \",X_val.shape)\n",
    "print(\"X_test = \",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xây dựng model sử dụng Transfer Learning với mạng VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(64,64,3)\n",
    "filter_size = (3,3)\n",
    "pool_size = (2, 2)\n",
    "output_size = 43\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, filter_size, activation=\"relu\", padding=\"same\", input_shape=(64, 64, 3)))\n",
    "model.add(Conv2D(16, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(32, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(64, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(64, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(128, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(128, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(256, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(256, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(256, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(output_size, activation='softmax'))\n",
    "          \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1471/1471 [==============================] - 324s 220ms/step - loss: 1.2883 - accuracy: 0.6420 - val_loss: 0.3531 - val_accuracy: 0.9023\n",
      "Epoch 2/10\n",
      "1471/1471 [==============================] - 314s 214ms/step - loss: 0.2133 - accuracy: 0.9415 - val_loss: 0.1775 - val_accuracy: 0.9523\n",
      "Epoch 3/10\n",
      "1471/1471 [==============================] - 310s 211ms/step - loss: 0.1118 - accuracy: 0.9699 - val_loss: 0.0897 - val_accuracy: 0.9783\n",
      "Epoch 4/10\n",
      "1471/1471 [==============================] - 310s 211ms/step - loss: 0.0834 - accuracy: 0.9779 - val_loss: 0.1058 - val_accuracy: 0.9717\n",
      "Epoch 5/10\n",
      "1471/1471 [==============================] - 310s 210ms/step - loss: 0.0586 - accuracy: 0.9847 - val_loss: 0.0634 - val_accuracy: 0.9833\n",
      "Epoch 6/10\n",
      "1471/1471 [==============================] - 310s 211ms/step - loss: 0.0483 - accuracy: 0.9880 - val_loss: 0.0755 - val_accuracy: 0.9820\n",
      "Epoch 7/10\n",
      "1471/1471 [==============================] - 310s 211ms/step - loss: 0.0395 - accuracy: 0.9894 - val_loss: 0.0434 - val_accuracy: 0.9888\n",
      "Epoch 8/10\n",
      "1471/1471 [==============================] - 311s 212ms/step - loss: 0.0366 - accuracy: 0.9916 - val_loss: 0.0461 - val_accuracy: 0.9880\n",
      "Epoch 9/10\n",
      "1471/1471 [==============================] - 314s 214ms/step - loss: 0.0364 - accuracy: 0.9921 - val_loss: 0.0617 - val_accuracy: 0.9858\n",
      "Epoch 10/10\n",
      "1471/1471 [==============================] - 311s 211ms/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 0.4414 - val_accuracy: 0.9357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c101f055b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"traffic_sign_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"traffic_sign_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 13s 53ms/step - loss: 0.4334 - accuracy: 0.9374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43342065811157227, 0.9373884201049805]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
