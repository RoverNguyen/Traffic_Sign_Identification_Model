{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Indentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install -r setup_lib.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from imageio import imread\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow\n",
    "import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Load Data ảnh có dạng *.ppm và nhãn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'GTSRB/Final_Training/Images'\n",
    "pixels = []\n",
    "labels = []\n",
    "# Loop qua các thư mục trong thư mục Images\n",
    "for dir in os.listdir(data_path):\n",
    "    # Bỏ qua file .DS_Store của máy MacOS\n",
    "    if dir == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    # Đọc file csv để lấy thông tin về ảnh\n",
    "    class_dir = os.path.join(data_path, dir)\n",
    "    info_file = pd.read_csv(os.path.join(class_dir, \"GT-\" + dir + '.csv'), sep=';')\n",
    "\n",
    "    # Lăp trong file\n",
    "    for row in info_file.iterrows():\n",
    "        # Đọc ảnh\n",
    "        pixel = imread(os.path.join(class_dir, row[1].Filename))\n",
    "        # Trích phần ROI theo thông tin trong file csv\n",
    "        pixel = pixel[row[1]['Roi.X1']:row[1]['Roi.X2'], row[1]['Roi.Y1']:row[1]['Roi.Y2'], :]\n",
    "        # Resize về kích cỡ chuẩn\n",
    "        img = cv2.resize(pixel, (64,64))\n",
    "\n",
    "        # Thêm vào list dữ liệu\n",
    "        pixels.append(img)\n",
    "\n",
    "        # Thêm nhãn cho ảnh\n",
    "        labels.append(row[1].ClassId)\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trộn dữ liệu và chia dữ liệu thành 3 phần với tỉ lệ Train:Validation:Test = 6:2:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hoá dữ liệu pixels và labels\n",
    "pixels = np.array(pixels)\n",
    "labels = keras.utils.np_utils.to_categorical(labels)\n",
    "\n",
    "# Nhào trộn dữ liệu ngẫu nhiên\n",
    "randomize = np.arange(len(pixels))\n",
    "np.random.shuffle(randomize)\n",
    "X = pixels[randomize]\n",
    "y = labels[randomize]\n",
    "\n",
    "print(\"X = \",X.shape)\n",
    "\n",
    "# Chia dữ liệu theo tỷ lệ 60% train và 40% còn lại cho val và test\n",
    "train_size = int(X.shape[0] * 0.6)\n",
    "X_train, X_val_test = X[:train_size], X[train_size:]\n",
    "y_train, y_val_test = y[:train_size], y[train_size:]\n",
    "\n",
    "val_size = int(X_val_test.shape[0] * 0.5) # 50% của phần 40% bên trên\n",
    "X_val, X_test = X_val_test[:val_size], X_val_test[val_size:]\n",
    "y_val, y_test = y_val_test[:val_size], y_val_test[val_size:]\n",
    "\n",
    "print(\"X_train = \",X_train.shape)\n",
    "print(\"X_val = \",X_val.shape)\n",
    "print(\"X_test = \",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xây dựng model sử dụng Transfer Learning với mạng VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(64,64,3)\n",
    "filter_size = (3,3)\n",
    "pool_size = (2, 2)\n",
    "output_size = 43\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, filter_size, activation=\"relu\", padding=\"same\", input_shape=(64, 64, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(256, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, filter_size, activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(output_size, activation='softmax'))\n",
    "          \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1471/1471 [==============================] - 348s 236ms/step - loss: 1.2528 - accuracy: 0.6303 - val_loss: 0.3138 - val_accuracy: 0.8975\n",
      "Epoch 2/10\n",
      "1471/1471 [==============================] - 356s 242ms/step - loss: 0.1674 - accuracy: 0.9470 - val_loss: 0.1062 - val_accuracy: 0.9689\n",
      "Epoch 3/10\n",
      "1471/1471 [==============================] - 357s 243ms/step - loss: 0.0815 - accuracy: 0.9744 - val_loss: 0.0850 - val_accuracy: 0.9769\n",
      "Epoch 4/10\n",
      "1471/1471 [==============================] - 353s 240ms/step - loss: 0.0575 - accuracy: 0.9824 - val_loss: 0.1240 - val_accuracy: 0.9626\n",
      "Epoch 5/10\n",
      "1471/1471 [==============================] - 360s 245ms/step - loss: 0.0480 - accuracy: 0.9856 - val_loss: 0.0765 - val_accuracy: 0.9818\n",
      "Epoch 6/10\n",
      "1471/1471 [==============================] - 358s 243ms/step - loss: 0.0401 - accuracy: 0.9881 - val_loss: 0.0492 - val_accuracy: 0.9862\n",
      "Epoch 7/10\n",
      "1471/1471 [==============================] - 358s 243ms/step - loss: 0.0299 - accuracy: 0.9914 - val_loss: 0.0670 - val_accuracy: 0.9800\n",
      "Epoch 8/10\n",
      "1471/1471 [==============================] - 359s 244ms/step - loss: 0.0328 - accuracy: 0.9911 - val_loss: 0.0401 - val_accuracy: 0.9889\n",
      "Epoch 9/10\n",
      "1471/1471 [==============================] - 359s 244ms/step - loss: 0.0276 - accuracy: 0.9924 - val_loss: 0.0943 - val_accuracy: 0.9721\n",
      "Epoch 10/10\n",
      "1471/1471 [==============================] - 360s 245ms/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.0575 - val_accuracy: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f930340d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"traffic_sign_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"traffic_sign_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 17s 68ms/step - loss: 0.0740 - accuracy: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07396675646305084, 0.9849528074264526]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
